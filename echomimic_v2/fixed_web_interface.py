import gradio as gr
import os
import sys
import subprocess
import time
import shutil
import yaml
from pathlib import Path
from PIL import Image
import librosa
import soundfile as sf

class EchoMimicApp:
    def __init__(self):
        self.project_root = Path.cwd()
        self.temp_dir = self.project_root / "temp_uploads"
        self.temp_dir.mkdir(exist_ok=True)
        
        # åŠ è½½åŸºç¡€é…ç½®æ¨¡æ¿
        self.base_config = self.load_base_config()
        
        # åŠ è½½é¡¹ç›®èµ„æº
        self.poses, self.images, self.audios = self.load_assets()
    
    def load_base_config(self):
        """åŠ è½½åŸºç¡€é…ç½®æ¨¡æ¿"""
        base_config_path = self.project_root / "configs/prompts/infer.yaml"
        
        if base_config_path.exists():
            try:
                with open(base_config_path, 'r', encoding='utf-8') as f:
                    base_config = yaml.safe_load(f)
                print(f"âœ… åŠ è½½åŸºç¡€é…ç½®: {base_config_path}")
                return base_config
            except Exception as e:
                print(f"âš ï¸ åŸºç¡€é…ç½®åŠ è½½å¤±è´¥: {e}")
        
        # é»˜è®¤é…ç½®
        return {
            'model_path': './pretrained_weights',
            'pretrained_base_model_path': './pretrained_weights/sd-image-variations-diffusers',
            'pretrained_vae_path': './pretrained_weights/sd-vae-ft-mse',
            'denoising_unet_path': './pretrained_weights/denoising_unet.pth',
            'reference_unet_path': './pretrained_weights/reference_unet.pth',
            'pose_encoder_path': './pretrained_weights/pose_encoder.pth',
            'motion_module_path': './pretrained_weights/motion_module.pth',
            'audio_mapper_path': './pretrained_weights/audio_mapper-50000.pth',
            'auido_guider_path': './pretrained_weights/wav2vec2-base-960h',
            'auto_flow_path': './pretrained_weights/AutoFlow',
            'audio_model_path': './pretrained_weights/audio_processor/tiny.pt',
            'inference_config': './configs/inference/inference_v2.yaml',
            'weight_dtype': 'fp16',
            'output_dir': './outputs',
            'seed': 42,
            'output_fps': 25
        }
    
    def load_assets(self):
        """åŠ è½½é¡¹ç›®èµ„æº"""
        
        # åŠ è½½å§¿åŠ¿é¢„è®¾
        pose_dir = self.project_root / "assets/halfbody_demo/pose"
        poses = []
        if pose_dir.exists():
            poses = [d.name for d in pose_dir.iterdir() if d.is_dir()]
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å§¿åŠ¿ç›®å½•ï¼Œå°è¯•å…¶ä»–ä½ç½®
        if not poses:
            for possible_dir in ["assets/pose", "examples/pose", "demo/pose"]:
                test_dir = self.project_root / possible_dir
                if test_dir.exists():
                    poses = [d.name for d in test_dir.iterdir() if d.is_dir()]
                    break
        
        # å¦‚æœè¿˜æ²¡æœ‰ï¼Œåˆ›å»ºé»˜è®¤å§¿åŠ¿
        if not poses:
            poses = ["default"]
        
        # åŠ è½½å‚è€ƒå›¾åƒ
        ref_dir = self.project_root / "assets/halfbody_demo/refimag"
        images = []
        if ref_dir.exists():
            for category in ref_dir.iterdir():
                if category.is_dir():
                    for img in category.glob("*.png"):
                        images.append(str(img))
        
        # åŠ è½½éŸ³é¢‘æ–‡ä»¶
        audio_dir = self.project_root / "assets/halfbody_demo/audio" 
        audios = []
        if audio_dir.exists():
            for audio in audio_dir.rglob("*.wav"):
                audios.append(str(audio))
        
        return poses, images, audios
    
    def preprocess_custom_image(self, image_file, target_size=(512, 512)):
        """å¤„ç†ç”¨æˆ·ä¸Šä¼ çš„è‡ªå®šä¹‰å›¾åƒ"""
        
        if not image_file:
            return None, "âŒ æœªä¸Šä¼ å›¾åƒæ–‡ä»¶"
        
        try:
            # æ‰“å¼€å›¾åƒ
            img = Image.open(image_file.name)
            
            # è½¬æ¢ä¸ºRGB
            if img.mode != 'RGB':
                img = img.convert('RGB')
            
            # è·å–åŸå§‹å°ºå¯¸
            original_size = img.size
            
            # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼Œä¿æŒé•¿å®½æ¯”
            aspect_ratio = original_size[0] / original_size[1]
            
            if aspect_ratio > 1:  # å®½å›¾
                new_width = target_size[0]
                new_height = int(target_size[0] / aspect_ratio)
            else:  # é«˜å›¾æˆ–æ­£æ–¹å½¢
                new_height = target_size[1]
                new_width = int(target_size[1] * aspect_ratio)
            
            # ç¼©æ”¾å›¾åƒ
            img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
            
            # åˆ›å»ºç›®æ ‡å°ºå¯¸çš„é»‘è‰²èƒŒæ™¯
            canvas = Image.new('RGB', target_size, (0, 0, 0))
            
            # å±…ä¸­ç²˜è´´
            paste_x = (target_size[0] - new_width) // 2
            paste_y = (target_size[1] - new_height) // 2
            canvas.paste(img, (paste_x, paste_y))
            
            # ä¿å­˜å¤„ç†åçš„å›¾åƒ
            processed_path = self.temp_dir / f"custom_image_{int(time.time())}.png"
            canvas.save(processed_path)
            
            return str(processed_path), f"âœ… å›¾åƒå¤„ç†æˆåŠŸ\nåŸå§‹å°ºå¯¸: {original_size[0]}x{original_size[1]}\nå¤„ç†å: {target_size[0]}x{target_size[1]}"
            
        except Exception as e:
            return None, f"âŒ å›¾åƒå¤„ç†å¤±è´¥: {str(e)}"
    
    def preprocess_custom_audio(self, audio_file, target_sr=16000, max_duration=30):
        """å¤„ç†ç”¨æˆ·ä¸Šä¼ çš„è‡ªå®šä¹‰éŸ³é¢‘"""
        
        if not audio_file:
            return None, "âŒ æœªä¸Šä¼ éŸ³é¢‘æ–‡ä»¶"
        
        try:
            # åŠ è½½éŸ³é¢‘
            audio, sr = librosa.load(audio_file.name, sr=None)
            original_duration = len(audio) / sr
            
            # é™åˆ¶éŸ³é¢‘é•¿åº¦
            if original_duration > max_duration:
                audio = audio[:int(max_duration * sr)]
                duration_info = f"âš ï¸ éŸ³é¢‘å·²æˆªæ–­è‡³{max_duration}ç§’"
            else:
                duration_info = f"âœ… éŸ³é¢‘é•¿åº¦: {original_duration:.2f}ç§’"
            
            # é‡é‡‡æ ·
            if sr != target_sr:
                audio = librosa.resample(audio, orig_sr=sr, target_sr=target_sr)
                sr = target_sr
            
            # å½’ä¸€åŒ–
            audio = librosa.util.normalize(audio)
            
            # ä¿å­˜å¤„ç†åçš„éŸ³é¢‘
            processed_path = self.temp_dir / f"custom_audio_{int(time.time())}.wav"
            sf.write(processed_path, audio, sr)
            
            return str(processed_path), f"{duration_info}\né‡‡æ ·ç‡: {sr}Hz\nâœ… éŸ³é¢‘å¤„ç†å®Œæˆ"
            
        except Exception as e:
            return None, f"âŒ éŸ³é¢‘å¤„ç†å¤±è´¥: {str(e)}"
    
    def create_dynamic_config(self, ref_image_path, audio_path, pose_preset):
        """åˆ›å»ºåŠ¨æ€é…ç½®æ–‡ä»¶ - å…³é”®ä¿®å¤ï¼"""
        
        # å¤åˆ¶åŸºç¡€é…ç½®
        dynamic_config = self.base_config.copy()
        
        # ğŸ¯ å…³é”®ä¿®å¤ï¼šè®¾ç½®ç”¨æˆ·çš„è¾“å…¥æ–‡ä»¶è·¯å¾„
        dynamic_config['reference_image'] = ref_image_path
        dynamic_config['audio_path'] = audio_path
        
        # è®¾ç½®å§¿åŠ¿ç›®å½•
        if pose_preset == "default":
            # åˆ›å»ºé»˜è®¤å§¿åŠ¿ç›®å½•
            default_pose_dir = self.temp_dir / "default_pose"
            default_pose_dir.mkdir(exist_ok=True)
            
            # åˆ›å»ºä¸€ä¸ªç®€å•çš„å§¿åŠ¿æ–‡ä»¶
            pose_file = default_pose_dir / "pose_001.json"
            if not pose_file.exists():
                with open(pose_file, 'w') as f:
                    f.write('{}')  # ç©ºçš„å§¿åŠ¿æ–‡ä»¶
            
            dynamic_config['pose_dir'] = str(default_pose_dir)
        else:
            # ä½¿ç”¨é€‰å®šçš„å§¿åŠ¿é¢„è®¾
            pose_path = self.project_root / "assets/halfbody_demo/pose" / pose_preset
            if not pose_path.exists():
                # å°è¯•å…¶ä»–å¯èƒ½çš„ä½ç½®
                for possible_dir in ["assets/pose", "examples/pose", "demo/pose"]:
                    test_path = self.project_root / possible_dir / pose_preset
                    if test_path.exists():
                        pose_path = test_path
                        break
            
            dynamic_config['pose_dir'] = str(pose_path)
        
        # è®¾ç½®è¾“å‡ºç›®å½•
        dynamic_config['output_dir'] = str(self.project_root / "outputs")
        
        # ä¿å­˜åŠ¨æ€é…ç½®æ–‡ä»¶
        config_path = self.temp_dir / f"dynamic_config_{int(time.time())}.yaml"
        
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(dynamic_config, f, default_flow_style=False, allow_unicode=True)
        
        # ğŸ” è°ƒè¯•è¾“å‡º
        print(f"ğŸ”§ åˆ›å»ºåŠ¨æ€é…ç½®æ–‡ä»¶: {config_path}")
        print(f"   ğŸ“¸ å‚è€ƒå›¾åƒ: {dynamic_config['reference_image']}")
        print(f"   ğŸµ éŸ³é¢‘æ–‡ä»¶: {dynamic_config['audio_path']}")
        print(f"   ğŸ•º å§¿åŠ¿ç›®å½•: {dynamic_config['pose_dir']}")
        
        return str(config_path)
    
    def generate_digital_human(self, use_custom_image, custom_image, preset_image, 
                             use_custom_audio, custom_audio, preset_audio, pose_preset):
        """ç”Ÿæˆæ•°å­—äººè§†é¢‘"""
        
        try:
            status = "ğŸ¬ å¼€å§‹ç”Ÿæˆæ•°å­—äººè§†é¢‘...\n"
            
            # å¤„ç†å›¾åƒè¾“å…¥
            if use_custom_image and custom_image:
                status += "ğŸ“¸ å¤„ç†è‡ªå®šä¹‰å›¾åƒ...\n"
                ref_image_path, img_msg = self.preprocess_custom_image(custom_image)
                if not ref_image_path:
                    return None, status + img_msg
                status += img_msg + "\n\n"
            else:
                if not preset_image:
                    return None, status + "âŒ è¯·é€‰æ‹©é¢„è®¾å›¾åƒ"
                ref_image_path = preset_image
                status += f"ğŸ“¸ ä½¿ç”¨é¢„è®¾å›¾åƒ: {Path(preset_image).name}\n\n"
            
            # å¤„ç†éŸ³é¢‘è¾“å…¥
            if use_custom_audio and custom_audio:
                status += "ğŸµ å¤„ç†è‡ªå®šä¹‰éŸ³é¢‘...\n"
                audio_path, audio_msg = self.preprocess_custom_audio(custom_audio)
                if not audio_path:
                    return None, status + audio_msg
                status += audio_msg + "\n\n"
            else:
                if not preset_audio:
                    return None, status + "âŒ è¯·é€‰æ‹©é¢„è®¾éŸ³é¢‘"
                audio_path = preset_audio
                status += f"ğŸµ ä½¿ç”¨é¢„è®¾éŸ³é¢‘: {Path(preset_audio).name}\n\n"
            
            status += f"ğŸ¤– ä½¿ç”¨å§¿åŠ¿é¢„è®¾: {pose_preset}\n\n"
            
            # ğŸ¯ å…³é”®ä¿®å¤ï¼šåˆ›å»ºåŠ¨æ€é…ç½®æ–‡ä»¶
            config_path = self.create_dynamic_config(ref_image_path, audio_path, pose_preset)
            status += f"âš™ï¸ é…ç½®æ–‡ä»¶å·²åˆ›å»º: {Path(config_path).name}\n\n"
            
            # ğŸ¯ å…³é”®ä¿®å¤ï¼šä½¿ç”¨åŠ¨æ€é…ç½®æ–‡ä»¶è¿è¡Œæ¨ç†
            cmd = [sys.executable, "infer.py", f"--config={config_path}"]
            
            status += "âš¡ æ­£åœ¨ç”Ÿæˆè§†é¢‘ï¼Œä½¿ç”¨ä½ çš„ç…§ç‰‡å’Œå£°éŸ³...\n"
            status += f"ğŸ”§ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}\n\n"
            
            start_time = time.time()
            
            # æ‰§è¡Œæ¨ç†
            result = subprocess.run(
                cmd, 
                cwd=str(self.project_root), 
                capture_output=True, 
                text=True, 
                timeout=900  # 15åˆ†é’Ÿè¶…æ—¶
            )
            
            duration = time.time() - start_time
            status += f"â±ï¸ å¤„ç†è€—æ—¶: {duration:.1f}ç§’\n"
            
            # æ·»åŠ æ¨ç†è¿‡ç¨‹è¾“å‡º
            if result.stdout:
                status += f"\nğŸ“‹ æ¨ç†è¾“å‡º:\n{result.stdout[:500]}...\n"
            
            if result.stderr:
                status += f"\nâš ï¸ é”™è¯¯ä¿¡æ¯:\n{result.stderr[:500]}...\n"
            
            # æŸ¥æ‰¾ç”Ÿæˆçš„è§†é¢‘
            output_dir = self.project_root / "outputs"
            if output_dir.exists():
                video_files = list(output_dir.rglob("*.mp4"))
                if video_files:
                    # æ‰¾åˆ°æœ€æ–°ç”Ÿæˆçš„è§†é¢‘
                    latest_video = max(video_files, key=lambda x: x.stat().st_mtime)
                    
                    # å¦‚æœä½¿ç”¨äº†è‡ªå®šä¹‰å†…å®¹ï¼Œé‡å‘½åè§†é¢‘æ–‡ä»¶ä»¥ä¾¿è¯†åˆ«
                    if use_custom_image or use_custom_audio:
                        custom_name = "custom_"
                        if use_custom_image:
                            custom_name += "img_"
                        if use_custom_audio:
                            custom_name += "audio_"
                        custom_name += f"{int(time.time())}.mp4"
                        
                        new_path = latest_video.parent / custom_name
                        shutil.copy2(latest_video, new_path)
                        latest_video = new_path
                    
                    status += f"âœ… è§†é¢‘ç”ŸæˆæˆåŠŸï¼\nğŸ“ ä¿å­˜ä½ç½®: {latest_video}\n"
                    status += "ğŸ‰ ä½ çš„ä¸ªæ€§åŒ–æ•°å­—äººå·²ç»å‡†å¤‡å¥½äº†ï¼"
                    return str(latest_video), status
            
            status += "âŒ æœªæ‰¾åˆ°ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶\n"
            status += "ğŸ’¡ è¯·æ£€æŸ¥æ¨ç†è„šæœ¬æ˜¯å¦æ­£å¸¸è¿è¡Œ"
            return None, status
            
        except subprocess.TimeoutExpired:
            return None, status + "âŒ ç”Ÿæˆè¶…æ—¶ï¼ˆè¶…è¿‡15åˆ†é’Ÿï¼‰\nğŸ’¡ è¯·å°è¯•ä½¿ç”¨æ›´çŸ­çš„éŸ³é¢‘æ–‡ä»¶"
        except Exception as e:
            return None, status + f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}\nğŸ’¡ è¯·æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ ¼å¼å’Œæ¨ç†è„šæœ¬"
    
    def create_interface(self):
        """åˆ›å»ºWebç•Œé¢"""
        
        with gr.Blocks(title="EchoMimicæ•°å­—äººç”Ÿæˆå™¨", theme=gr.themes.Soft()) as app:
            
            gr.HTML("""
            <div style="text-align: center; margin: 30px;">
                <h1 style="color: #2E8B57; font-size: 2.5em;">ğŸ­ EchoMimic æ•°å­—äººç”Ÿæˆå™¨</h1>
                <p style="color: #666; font-size: 18px;">åˆ›å»ºå±äºä½ çš„ä¸ªæ€§åŒ–æ•°å­—äººè§†é¢‘</p>
                <p style="color: #999; font-size: 14px;">âœ¨ ç°å·²ä¿®å¤ï¼šè‡ªåŠ¨ä½¿ç”¨ä½ ä¸Šä¼ çš„ç…§ç‰‡å’ŒéŸ³é¢‘ï¼</p>
            </div>
            """)
            
            with gr.Row():
                # å·¦ä¾§ï¼šå›¾åƒè®¾ç½®
                with gr.Column(scale=1):
                    gr.HTML("<h3 style='color: #4CAF50;'>ğŸ“¸ å›¾åƒè®¾ç½®</h3>")
                    
                    use_custom_image = gr.Checkbox(
                        label="ğŸ¯ ä½¿ç”¨æˆ‘çš„ç…§ç‰‡ (æ¨è)",
                        value=True  # é»˜è®¤å¯ç”¨è‡ªå®šä¹‰å›¾åƒ
                    )
                    
                    with gr.Group() as preset_img_group:
                        if self.images:
                            preset_image = gr.Dropdown(
                                choices=self.images,
                                label="é€‰æ‹©é¢„è®¾å›¾åƒ",
                                value=self.images[0] if self.images else None
                            )
                            preset_img_preview = gr.Image(
                                label="é¢„è®¾å›¾åƒé¢„è§ˆ", 
                                interactive=False,
                                height=200
                            )
                        else:
                            preset_image = gr.HTML("<p>âš ï¸ æœªæ‰¾åˆ°é¢„è®¾å›¾åƒï¼Œè¯·ä¸Šä¼ è‡ªå®šä¹‰å›¾åƒ</p>")
                            preset_img_preview = None
                    
                    with gr.Group(visible=True) as custom_img_group:  # é»˜è®¤æ˜¾ç¤º
                        custom_image = gr.File(
                            label="ğŸ“· ä¸Šä¼ ä½ çš„ç…§ç‰‡",
                            file_types=[".jpg", ".jpeg", ".png", ".bmp"]
                        )
                        custom_img_preview = gr.Image(
                            label="ä½ çš„ç…§ç‰‡é¢„è§ˆ",
                            interactive=False,
                            height=200
                        )
                        gr.HTML("<p style='color: #666; font-size: 12px;'>ğŸ’¡ å»ºè®®ä½¿ç”¨æ¸…æ™°çš„æ­£é¢ç…§ç‰‡ï¼Œæ”¯æŒJPG/PNGæ ¼å¼</p>")
                
                # ä¸­é—´ï¼šéŸ³é¢‘è®¾ç½®
                with gr.Column(scale=1):
                    gr.HTML("<h3 style='color: #4CAF50;'>ğŸµ éŸ³é¢‘è®¾ç½®</h3>")
                    
                    use_custom_audio = gr.Checkbox(
                        label="ğŸ¯ ä½¿ç”¨æˆ‘çš„å£°éŸ³ (æ¨è)",
                        value=True  # é»˜è®¤å¯ç”¨è‡ªå®šä¹‰éŸ³é¢‘
                    )
                    
                    with gr.Group() as preset_audio_group:
                        if self.audios:
                            preset_audio = gr.Dropdown(
                                choices=self.audios,
                                label="é€‰æ‹©é¢„è®¾éŸ³é¢‘",
                                value=self.audios[0] if self.audios else None
                            )
                            preset_audio_preview = gr.Audio(
                                label="é¢„è®¾éŸ³é¢‘è¯•å¬",
                                interactive=False
                            )
                        else:
                            preset_audio = gr.HTML("<p>âš ï¸ æœªæ‰¾åˆ°é¢„è®¾éŸ³é¢‘ï¼Œè¯·ä¸Šä¼ è‡ªå®šä¹‰éŸ³é¢‘</p>")
                            preset_audio_preview = None
                    
                    with gr.Group(visible=True) as custom_audio_group:  # é»˜è®¤æ˜¾ç¤º
                        custom_audio = gr.File(
                            label="ğŸ¤ ä¸Šä¼ ä½ çš„éŸ³é¢‘",
                            file_types=[".wav", ".mp3", ".m4a", ".flac"]
                        )
                        custom_audio_preview = gr.Audio(
                            label="ä½ çš„éŸ³é¢‘è¯•å¬",
                            interactive=False
                        )
                        gr.HTML("<p style='color: #666; font-size: 12px;'>ğŸ’¡ å»ºè®®æ—¶é•¿10-30ç§’ï¼Œæ”¯æŒWAV/MP3æ ¼å¼</p>")
                
                # å³ä¾§ï¼šå…¶ä»–è®¾ç½®
                with gr.Column(scale=1):
                    gr.HTML("<h3 style='color: #4CAF50;'>ğŸ¤– å§¿åŠ¿è®¾ç½®</h3>")
                    
                    pose_preset = gr.Dropdown(
                        choices=self.poses,
                        label="é€‰æ‹©å§¿åŠ¿é¢„è®¾",
                        value=self.poses[0] if self.poses else "default"
                    )
                    
                    gr.HTML("<br>")
                    
                    generate_btn = gr.Button(
                        "ğŸ¬ ç”Ÿæˆæˆ‘çš„ä¸“å±æ•°å­—äºº",
                        variant="primary",
                        size="lg"
                    )
                    
                    gr.HTML("""
                    <div style="margin-top: 20px; padding: 10px; background-color: #f0f8f0; border-radius: 5px;">
                        <h4 style="color: #2E8B57;">âœ¨ ä¿®å¤è¯´æ˜</h4>
                        <ul style="color: #666; font-size: 12px;">
                            <li>âœ… ç°åœ¨ä¼šè‡ªåŠ¨ä½¿ç”¨ä½ ä¸Šä¼ çš„ç…§ç‰‡å’ŒéŸ³é¢‘</li>
                            <li>âœ… åŠ¨æ€åˆ›å»ºé…ç½®æ–‡ä»¶ï¼Œæ— éœ€æ‰‹åŠ¨ä¿®æ”¹</li>
                            <li>âœ… æ”¯æŒå¤šç§å›¾ç‰‡å’ŒéŸ³é¢‘æ ¼å¼</li>
                            <li>âœ… è‡ªåŠ¨å¤„ç†æ–‡ä»¶æ ¼å¼è½¬æ¢</li>
                        </ul>
                    </div>
                    """)
            
            # è¾“å‡ºåŒºåŸŸ
            with gr.Row():
                with gr.Column():
                    gr.HTML("<h3 style='color: #4CAF50;'>ğŸ“º ç”Ÿæˆç»“æœ</h3>")
                    
                    output_video = gr.Video(
                        label="ä½ çš„ä¸“å±æ•°å­—äººè§†é¢‘ ğŸ¯",
                        height=400
                    )
                    
                    status_text = gr.Textbox(
                        label="ç”ŸæˆçŠ¶æ€ (è¯¦ç»†æ—¥å¿—)",
                        lines=15,
                        interactive=False
                    )
            
            # äº‹ä»¶å¤„ç†
            def toggle_image_input(use_custom):
                return gr.Group.update(visible=not use_custom), gr.Group.update(visible=use_custom)
            
            def toggle_audio_input(use_custom):
                return gr.Group.update(visible=not use_custom), gr.Group.update(visible=use_custom)
            
            def update_preset_img_preview(img_path):
                return img_path if img_path and os.path.exists(img_path) else None
            
            def update_custom_img_preview(img_file):
                return img_file.name if img_file else None
            
            def update_preset_audio_preview(audio_path):
                return audio_path if audio_path and os.path.exists(audio_path) else None
            
            def update_custom_audio_preview(audio_file):
                return audio_file.name if audio_file else None
            
            # ç»‘å®šäº‹ä»¶
            use_custom_image.change(
                toggle_image_input,
                inputs=[use_custom_image],
                outputs=[preset_img_group, custom_img_group]
            )
            
            use_custom_audio.change(
                toggle_audio_input,
                inputs=[use_custom_audio],
                outputs=[preset_audio_group, custom_audio_group]
            )
            
            if self.images and preset_img_preview:
                preset_image.change(
                    update_preset_img_preview,
                    inputs=[preset_image],
                    outputs=[preset_img_preview]
                )
            
            custom_image.change(
                update_custom_img_preview,
                inputs=[custom_image],
                outputs=[custom_img_preview]
            )
            
            if self.audios and preset_audio_preview:
                preset_audio.change(
                    update_preset_audio_preview,
                    inputs=[preset_audio],
                    outputs=[preset_audio_preview]
                )
            
            custom_audio.change(
                update_custom_audio_preview,
                inputs=[custom_audio],
                outputs=[custom_audio_preview]
            )
            
            # ç”ŸæˆæŒ‰é’®äº‹ä»¶
            generate_btn.click(
                self.generate_digital_human,
                inputs=[
                    use_custom_image, custom_image, preset_image,
                    use_custom_audio, custom_audio, preset_audio, 
                    pose_preset
                ],
                outputs=[output_video, status_text]
            )
        
        return app

def main():
    """å¯åŠ¨åº”ç”¨"""
    
    print("ğŸš€ å¯åŠ¨EchoMimicä¿®å¤ç‰ˆWebç•Œé¢...")
    print("ğŸ¯ å…³é”®ä¿®å¤ï¼šç°åœ¨ä¼šè‡ªåŠ¨ä½¿ç”¨ç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶ï¼")
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not Path("infer.py").exists():
        print("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°infer.pyï¼Œè¯·åœ¨EchoMimicé¡¹ç›®æ ¹ç›®å½•è¿è¡Œ")
        return
    
    try:
        app = EchoMimicApp()
        interface = app.create_interface()
        
        print("ğŸŒ Webç•Œé¢å·²å¯åŠ¨")
        print("ğŸ“ è®¿é—®åœ°å€: http://127.0.0.1:7860")
        print("âœ… ä¿®å¤å®Œæˆï¼šä¸Šä¼ çš„ç…§ç‰‡å’ŒéŸ³é¢‘ç°åœ¨ä¼šè¢«æ­£ç¡®ä½¿ç”¨ï¼")
        
        interface.launch(
            server_name="127.0.0.1",
            server_port=7860,
            inbrowser=True,
            share=False
        )
    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")

if __name__ == "__main__":
    main()