import gradio as gr
import os
import sys
import torch
import subprocess
import shutil
import json
import time
from pathlib import Path
import yaml
import cv2
import numpy as np
from PIL import Image
import librosa
import soundfile as sf

class EchoMimicWebApp:
    def __init__(self):
        self.project_root = Path("D:/PythonProjects/DigitalHuman/echomimic_v2")
        self.output_dir = self.project_root / "outputs"
        self.temp_dir = self.project_root / "temp_uploads"
        self.temp_dir.mkdir(exist_ok=True)
        
        # é¢„è®¾å§¿åŠ¿å’Œå‚è€ƒå›¾åƒè·¯å¾„
        self.pose_presets = self._load_pose_presets()
        self.reference_images = self._load_reference_images()
        
    def _load_pose_presets(self):
        """åŠ è½½é¢„è®¾å§¿åŠ¿"""
        pose_dir = self.project_root / "assets" / "halfbody_demo" / "pose"
        presets = {}
        if pose_dir.exists():
            for pose_folder in pose_dir.iterdir():
                if pose_folder.is_dir():
                    presets[pose_folder.name] = str(pose_folder)
        return presets
    
    def _load_reference_images(self):
        """åŠ è½½é¢„è®¾å‚è€ƒå›¾åƒ"""
        ref_dir = self.project_root / "assets" / "halfbody_demo" / "refimag"
        images = {}
        if ref_dir.exists():
            for category in ref_dir.iterdir():
                if category.is_dir():
                    category_images = []
                    for img_file in category.glob("*.png"):
                        category_images.append((img_file.name, str(img_file)))
                    if category_images:
                        images[category.name] = category_images
        return images
    
    def preprocess_image(self, image_path, target_size=(512, 512)):
        """é¢„å¤„ç†ç”¨æˆ·ä¸Šä¼ çš„å›¾åƒ"""
        try:
            # æ‰“å¼€å›¾åƒ
            image = Image.open(image_path)
            
            # è½¬æ¢ä¸ºRGB
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # è·å–åŸå§‹å°ºå¯¸
            original_width, original_height = image.size
            
            # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼Œä¿æŒé•¿å®½æ¯”
            aspect_ratio = original_width / original_height
            target_width, target_height = target_size
            
            if aspect_ratio > 1:  # å®½å›¾
                new_width = target_width
                new_height = int(target_width / aspect_ratio)
            else:  # é«˜å›¾æˆ–æ­£æ–¹å½¢
                new_height = target_height
                new_width = int(target_height * aspect_ratio)
            
            # ç¼©æ”¾å›¾åƒ
            image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
            
            # åˆ›å»ºç›®æ ‡å°ºå¯¸çš„ç”»å¸ƒï¼ŒèƒŒæ™¯ä¸ºé»‘è‰²
            canvas = Image.new('RGB', target_size, (0, 0, 0))
            
            # è®¡ç®—ç²˜è´´ä½ç½®ï¼ˆå±…ä¸­ï¼‰
            paste_x = (target_width - new_width) // 2
            paste_y = (target_height - new_height) // 2
            
            # ç²˜è´´å›¾åƒ
            canvas.paste(image, (paste_x, paste_y))
            
            # ä¿å­˜å¤„ç†åçš„å›¾åƒ
            processed_path = self.temp_dir / f"processed_{int(time.time())}.png"
            canvas.save(processed_path)
            
            return str(processed_path), f"âœ… å›¾åƒå¤„ç†å®Œæˆ\nåŸå§‹å°ºå¯¸: {original_width}x{original_height}\nå¤„ç†åå°ºå¯¸: {target_size[0]}x{target_size[1]}"
            
        except Exception as e:
            return None, f"âŒ å›¾åƒå¤„ç†å¤±è´¥: {str(e)}"
    
    def preprocess_audio(self, audio_path, target_sr=16000, max_duration=30):
        """é¢„å¤„ç†ç”¨æˆ·ä¸Šä¼ çš„éŸ³é¢‘"""
        try:
            # åŠ è½½éŸ³é¢‘
            audio, sr = librosa.load(audio_path, sr=None)
            
            # é™åˆ¶éŸ³é¢‘é•¿åº¦
            if len(audio) / sr > max_duration:
                audio = audio[:int(max_duration * sr)]
                duration_info = f"âš ï¸ éŸ³é¢‘å·²æˆªæ–­è‡³{max_duration}ç§’"
            else:
                duration_info = f"âœ… éŸ³é¢‘é•¿åº¦: {len(audio)/sr:.2f}ç§’"
            
            # é‡é‡‡æ ·åˆ°ç›®æ ‡é‡‡æ ·ç‡
            if sr != target_sr:
                audio = librosa.resample(audio, orig_sr=sr, target_sr=target_sr)
                sr = target_sr
            
            # å½’ä¸€åŒ–éŸ³é¢‘
            audio = librosa.util.normalize(audio)
            
            # ä¿å­˜å¤„ç†åçš„éŸ³é¢‘
            processed_path = self.temp_dir / f"processed_audio_{int(time.time())}.wav"
            sf.write(processed_path, audio, sr)
            
            return str(processed_path), f"{duration_info}\né‡‡æ ·ç‡: {sr}Hz\nâœ… éŸ³é¢‘å¤„ç†å®Œæˆ"
            
        except Exception as e:
            return None, f"âŒ éŸ³é¢‘å¤„ç†å¤±è´¥: {str(e)}"
    
    def generate_video(self, reference_image, audio_file, pose_preset, use_custom_image, custom_image, use_custom_audio, custom_audio, progress=gr.Progress()):
        """ç”Ÿæˆæ•°å­—äººè§†é¢‘"""
        try:
            progress(0.1, "å‡†å¤‡è¾“å…¥æ–‡ä»¶...")
            
            # ç¡®å®šå‚è€ƒå›¾åƒ
            if use_custom_image and custom_image:
                progress(0.2, "å¤„ç†è‡ªå®šä¹‰å›¾åƒ...")
                ref_img_path, img_msg = self.preprocess_image(custom_image)
                if not ref_img_path:
                    return None, f"âŒ {img_msg}"
                status_msg = f"ğŸ“¸ ä½¿ç”¨è‡ªå®šä¹‰å›¾åƒ\n{img_msg}\n"
            else:
                ref_img_path = reference_image
                status_msg = f"ğŸ“¸ ä½¿ç”¨é¢„è®¾å›¾åƒ: {Path(reference_image).name}\n"
            
            # ç¡®å®šéŸ³é¢‘æ–‡ä»¶
            if use_custom_audio and custom_audio:
                progress(0.3, "å¤„ç†è‡ªå®šä¹‰éŸ³é¢‘...")
                audio_path, audio_msg = self.preprocess_audio(custom_audio)
                if not audio_path:
                    return None, f"âŒ {audio_msg}"
                status_msg += f"ğŸµ ä½¿ç”¨è‡ªå®šä¹‰éŸ³é¢‘\n{audio_msg}\n"
            else:
                audio_path = audio_file
                status_msg += f"ğŸµ ä½¿ç”¨é¢„è®¾éŸ³é¢‘: {Path(audio_file).name}\n"
            
            # ç¡®å®šå§¿åŠ¿é¢„è®¾
            pose_path = self.pose_presets[pose_preset]
            status_msg += f"ğŸ¤– ä½¿ç”¨å§¿åŠ¿é¢„è®¾: {pose_preset}\n"
            
            progress(0.4, "åˆ›å»ºæ¨ç†é…ç½®...")
            
            # åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶
            config_data = {
                'pose_dir': pose_path,
                'ref_image_path': ref_img_path,
                'audio_path': audio_path,
                'output_dir': str(self.output_dir),
                'device': 'cuda' if torch.cuda.is_available() else 'cpu'
            }
            
            config_path = self.temp_dir / f"config_{int(time.time())}.yaml"
            with open(config_path, 'w', encoding='utf-8') as f:
                yaml.dump(config_data, f, default_flow_style=False, allow_unicode=True)
            
            progress(0.5, "å¯åŠ¨æ¨ç†è¿›ç¨‹...")
            
            # æ„å»ºæ¨ç†å‘½ä»¤
            cmd = [
                sys.executable, 
                "infer.py", 
                f"--config={config_path}"
            ]
            
            # è¿è¡Œæ¨ç†
            process = subprocess.Popen(
                cmd,
                cwd=str(self.project_root),
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                universal_newlines=True
            )
            
            # å®æ—¶è¯»å–è¾“å‡º
            output_lines = []
            while True:
                line = process.stdout.readline()
                if not line and process.poll() is not None:
                    break
                if line:
                    output_lines.append(line.strip())
                    # æ›´æ–°è¿›åº¦
                    if "%" in line and "|" in line:
                        try:
                            percent_str = line.split('%')[0].split()[-1]
                            if percent_str.replace('.', '').isdigit():
                                percent = float(percent_str) / 100
                                progress(0.5 + percent * 0.4, f"ç”Ÿæˆè§†é¢‘... {percent_str}%")
                        except:
                            pass
            
            progress(0.95, "æŸ¥æ‰¾ç”Ÿæˆçš„è§†é¢‘...")
            
            # æŸ¥æ‰¾ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶
            video_files = list(self.output_dir.rglob("*.mp4"))
            if video_files:
                # æ‰¾åˆ°æœ€æ–°çš„è§†é¢‘æ–‡ä»¶
                latest_video = max(video_files, key=lambda x: x.stat().st_mtime)
                
                progress(1.0, "è§†é¢‘ç”Ÿæˆå®Œæˆ!")
                
                return str(latest_video), f"âœ… è§†é¢‘ç”ŸæˆæˆåŠŸ!\n{status_msg}\nğŸ“ è¾“å‡ºè·¯å¾„: {latest_video}\n\næ¨ç†æ—¥å¿—:\n" + "\n".join(output_lines[-20:])
            else:
                return None, f"âŒ æœªæ‰¾åˆ°ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶\n{status_msg}\n\næ¨ç†æ—¥å¿—:\n" + "\n".join(output_lines)
                
        except Exception as e:
            return None, f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}\n{status_msg}"
    
    def create_interface(self):
        """åˆ›å»ºGradioç•Œé¢"""
        
        # CSSæ ·å¼
        css = """
        .gradio-container {
            font-family: 'Microsoft YaHei', Arial, sans-serif;
        }
        .title {
            text-align: center;
            color: #2E8B57;
            margin-bottom: 30px;
        }
        .section-header {
            background: linear-gradient(90deg, #4CAF50, #45a049);
            color: white;
            padding: 10px;
            border-radius: 5px;
            margin: 10px 0;
        }
        .status-box {
            background-color: #f0f8f0;
            border-left: 4px solid #4CAF50;
            padding: 15px;
            margin: 10px 0;
            border-radius: 5px;
        }
        """
        
        with gr.Blocks(css=css, title="EchoMimic æ•°å­—äººç”Ÿæˆå™¨") as interface:
            
            gr.HTML("""
            <h1 class="title">ğŸ­ EchoMimic æ•°å­—äººç”Ÿæˆå™¨</h1>
            <p style="text-align: center; color: #666; font-size: 18px;">
                åˆ›å»ºå±äºä½ çš„ä¸ªæ€§åŒ–æ•°å­—äººè§†é¢‘ - æ”¯æŒè‡ªå®šä¹‰å›¾åƒå’ŒéŸ³é¢‘
            </p>
            """)
            
            with gr.Row():
                with gr.Column(scale=1):
                    gr.HTML('<div class="section-header">ğŸ“¸ å›¾åƒè®¾ç½®</div>')
                    
                    use_custom_image = gr.Checkbox(
                        label="ä½¿ç”¨è‡ªå®šä¹‰å›¾åƒ",
                        value=False,
                        info="ä¸Šä¼ ä½ è‡ªå·±çš„ç…§ç‰‡ä½œä¸ºæ•°å­—äººå½¢è±¡"
                    )
                    
                    with gr.Group(visible=True) as preset_image_group:
                        # é¢„è®¾å›¾åƒé€‰æ‹©
                        ref_categories = list(self.reference_images.keys())
                        if ref_categories:
                            ref_category = gr.Dropdown(
                                choices=ref_categories,
                                label="å›¾åƒç±»åˆ«",
                                value=ref_categories[0] if ref_categories else None
                            )
                            
                            ref_image = gr.Dropdown(
                                choices=[img[0] for img in self.reference_images.get(ref_categories[0], [])] if ref_categories else [],
                                label="é€‰æ‹©é¢„è®¾å›¾åƒ",
                                value=self.reference_images[ref_categories[0]][0][0] if ref_categories and self.reference_images.get(ref_categories[0]) else None
                            )
                            
                            ref_preview = gr.Image(
                                label="é¢„è®¾å›¾åƒé¢„è§ˆ",
                                interactive=False,
                                height=200
                            )
                    
                    with gr.Group(visible=False) as custom_image_group:
                        custom_image = gr.File(
                            label="ä¸Šä¼ ä½ çš„ç…§ç‰‡",
                            file_types=[".jpg", ".jpeg", ".png", ".bmp"],
                            info="æ”¯æŒ JPG, PNG ç­‰æ ¼å¼ï¼Œå»ºè®®ä½¿ç”¨æ¸…æ™°çš„æ­£é¢ç…§ç‰‡"
                        )
                        
                        custom_preview = gr.Image(
                            label="è‡ªå®šä¹‰å›¾åƒé¢„è§ˆ",
                            interactive=False,
                            height=200
                        )
                
                with gr.Column(scale=1):
                    gr.HTML('<div class="section-header">ğŸµ éŸ³é¢‘è®¾ç½®</div>')
                    
                    use_custom_audio = gr.Checkbox(
                        label="ä½¿ç”¨è‡ªå®šä¹‰éŸ³é¢‘",
                        value=False,
                        info="ä¸Šä¼ ä½ è‡ªå·±çš„è¯­éŸ³æ–‡ä»¶"
                    )
                    
                    with gr.Group(visible=True) as preset_audio_group:
                        # é¢„è®¾éŸ³é¢‘é€‰æ‹©
                        audio_files = []
                        audio_dir = self.project_root / "assets" / "halfbody_demo" / "audio"
                        if audio_dir.exists():
                            for audio_file in audio_dir.rglob("*.wav"):
                                audio_files.append((audio_file.name, str(audio_file)))
                        
                        audio_file = gr.Dropdown(
                            choices=[audio[0] for audio in audio_files],
                            label="é€‰æ‹©é¢„è®¾éŸ³é¢‘",
                            value=audio_files[0][0] if audio_files else None
                        )
                        
                        preset_audio_player = gr.Audio(
                            label="é¢„è®¾éŸ³é¢‘è¯•å¬",
                            interactive=False
                        )
                    
                    with gr.Group(visible=False) as custom_audio_group:
                        custom_audio = gr.File(
                            label="ä¸Šä¼ ä½ çš„éŸ³é¢‘",
                            file_types=[".wav", ".mp3", ".m4a", ".flac"],
                            info="æ”¯æŒ WAV, MP3 ç­‰æ ¼å¼ï¼Œå»ºè®®æ—¶é•¿ä¸è¶…è¿‡30ç§’"
                        )
                        
                        custom_audio_player = gr.Audio(
                            label="è‡ªå®šä¹‰éŸ³é¢‘è¯•å¬",
                            interactive=False
                        )
                
                with gr.Column(scale=1):
                    gr.HTML('<div class="section-header">ğŸ¤– å§¿åŠ¿è®¾ç½®</div>')
                    
                    pose_preset = gr.Dropdown(
                        choices=list(self.pose_presets.keys()),
                        label="é€‰æ‹©å§¿åŠ¿é¢„è®¾",
                        value=list(self.pose_presets.keys())[0] if self.pose_presets else None,
                        info="ä¸åŒçš„å§¿åŠ¿åŠ¨ä½œåºåˆ—"
                    )
                    
                    gr.HTML('<div class="section-header">âš¡ ç”Ÿæˆæ§åˆ¶</div>')
                    
                    generate_btn = gr.Button(
                        "ğŸ¬ ç”Ÿæˆæ•°å­—äººè§†é¢‘",
                        variant="primary",
                        size="lg"
                    )
            
            with gr.Row():
                with gr.Column():
                    gr.HTML('<div class="section-header">ğŸ“º è¾“å‡ºç»“æœ</div>')
                    
                    output_video = gr.Video(
                        label="ç”Ÿæˆçš„æ•°å­—äººè§†é¢‘",
                        height=400
                    )
                    
                    status_output = gr.Textbox(
                        label="çŠ¶æ€ä¿¡æ¯",
                        lines=10,
                        max_lines=15,
                        interactive=False,
                        elem_classes=["status-box"]
                    )
            
            # äº‹ä»¶å¤„ç†å‡½æ•°
            def update_image_visibility(use_custom):
                return gr.Group.update(visible=not use_custom), gr.Group.update(visible=use_custom)
            
            def update_audio_visibility(use_custom):
                return gr.Group.update(visible=not use_custom), gr.Group.update(visible=use_custom)
            
            def update_ref_image_choices(category):
                if category in self.reference_images:
                    choices = [img[0] for img in self.reference_images[category]]
                    return gr.Dropdown.update(choices=choices, value=choices[0] if choices else None)
                return gr.Dropdown.update(choices=[], value=None)
            
            def update_ref_preview(category, image_name):
                if category in self.reference_images:
                    for img_name, img_path in self.reference_images[category]:
                        if img_name == image_name:
                            return img_path
                return None
            
            def update_custom_preview(file):
                if file:
                    return file.name
                return None
            
            def update_preset_audio(audio_name):
                audio_dir = self.project_root / "assets" / "halfbody_demo" / "audio"
                for audio_file in audio_dir.rglob("*.wav"):
                    if audio_file.name == audio_name:
                        return str(audio_file)
                return None
            
            def update_custom_audio_player(file):
                if file:
                    return file.name
                return None
            
            # ç»‘å®šäº‹ä»¶
            use_custom_image.change(
                update_image_visibility,
                inputs=[use_custom_image],
                outputs=[preset_image_group, custom_image_group]
            )
            
            use_custom_audio.change(
                update_audio_visibility,
                inputs=[use_custom_audio],
                outputs=[preset_audio_group, custom_audio_group]
            )
            
            if ref_categories:
                ref_category.change(
                    update_ref_image_choices,
                    inputs=[ref_category],
                    outputs=[ref_image]
                )
                
                ref_image.change(
                    update_ref_preview,
                    inputs=[ref_category, ref_image],
                    outputs=[ref_preview]
                )
            
            custom_image.change(
                update_custom_preview,
                inputs=[custom_image],
                outputs=[custom_preview]
            )
            
            if audio_files:
                audio_file.change(
                    update_preset_audio,
                    inputs=[audio_file],
                    outputs=[preset_audio_player]
                )
            
            custom_audio.change(
                update_custom_audio_player,
                inputs=[custom_audio],
                outputs=[custom_audio_player]
            )
            
            # ç”ŸæˆæŒ‰é’®äº‹ä»¶
            generate_btn.click(
                self.generate_video,
                inputs=[
                    # éœ€è¦ä¼ é€’å®é™…è·¯å¾„ï¼Œè¿™é‡Œéœ€è¦ä¿®æ”¹é€»è¾‘
                    gr.State(self.reference_images[ref_categories[0]][0][1] if ref_categories and self.reference_images.get(ref_categories[0]) else ""),
                    gr.State(audio_files[0][1] if audio_files else ""),
                    pose_preset,
                    use_custom_image,
                    custom_image,
                    use_custom_audio,
                    custom_audio
                ],
                outputs=[output_video, status_output]
            )
        
        return interface

# å¯åŠ¨åº”ç”¨
def main():
    app = EchoMimicWebApp()
    interface = app.create_interface()
    
    # å¯åŠ¨æœåŠ¡å™¨
    interface.launch(
        server_name="127.0.0.1",  # æœ¬åœ°è®¿é—®
        server_port=7860,        # ç«¯å£
        share=False,             # ä¸åˆ›å»ºå…¬å…±é“¾æ¥
        debug=True,              # è°ƒè¯•æ¨¡å¼
        show_error=True,         # æ˜¾ç¤ºé”™è¯¯
        inbrowser=True           # è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨
    )

if __name__ == "__main__":
    main()